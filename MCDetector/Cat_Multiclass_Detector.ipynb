{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cat_Multiclass_Detector",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPuSqMYM5tqi"
      },
      "source": [
        "Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAx_bg9Jratu"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1Lbk_pwATorDcUyk9VcGYzomLR4Rhj-lv #Downloading zip file from google drive\n",
        "zip_path = '/content/Cat_GAN_1.zip' #Getting the path \n",
        "!unzip -q Cat_GAN_1.zip #Unzipping the folder\n",
        "!rm Cat_GAN_1.zip #Removing the zip folder\n",
        "import os #Imported required libraries for this step\n",
        "import cv2\n",
        "import numpy as np\n",
        "os.mkdir(\"Training\") #making the new Training and testing folders\n",
        "os.mkdir(\"Testing\")\n",
        "dirs = [\"Domino\", \"Stormy\"] #Making the names for the subdirec\n",
        "pardirs = [\"/content/Training\", \"/content/Testing\"]\n",
        "for pardir in pardirs:\n",
        "  for dir in dirs:\n",
        "    path = os.path.join(pardir, dir)\n",
        "    os.mkdir(path)\n",
        "datadir1 = \"/content/Cat_Classifier_Images_70-30 /Train/Domino\"\n",
        "datadir2 = \"/content/Cat_Classifier_Images_70-30 /Train/Stormy\"\n",
        "datadir3 = \"/content/Cat_Classifier_Images_70-30 /Test/Domino\"\n",
        "datadir4 = \"/content/Cat_Classifier_Images_70-30 /Test/Stormy\"\n",
        "filelist1 = sorted(os.listdir(datadir1), key = lambda fname: int(fname.split(\"_\")[0][-4:]))\n",
        "filelist2 = sorted(os.listdir(datadir2), key = lambda fname: int(fname.split(\"_\")[0][-4:]))\n",
        "filelist3 = sorted(os.listdir(datadir3), key = lambda fname: int(fname.split(\"_\")[0][-4:]))\n",
        "filelist4 = sorted(os.listdir(datadir4), key = lambda fname: int(fname.split(\"_\")[0][-4:]))\n",
        "datadirs = [filelist1, filelist2, filelist3, filelist4]\n",
        "inc = 0\n",
        "idom = 0\n",
        "istorm = 0\n",
        "for filelist in datadirs:\n",
        "  for fil in filelist:\n",
        "    if inc == 0:\n",
        "      path = \"/content/Cat_Classifier_Images_70-30 /Train/Domino/\" + fil\n",
        "      idom += 1\n",
        "      img = cv2.imread(path)\n",
        "      imgResized = np.array((cv2.resize(img, (96, 128))))\n",
        "      cv2.imwrite('/content/Training/Domino/DominoTR%03i.jpg' %idom, imgResized)\n",
        "    elif inc == 1:\n",
        "      path = \"/content/Cat_Classifier_Images_70-30 /Train/Stormy/\" + fil\n",
        "      istorm += 1\n",
        "      img = cv2.imread(path)\n",
        "      imgResized = np.array((cv2.resize(img, (96, 128))))\n",
        "      cv2.imwrite('/content/Training/Stormy/StormyTR%03i.jpg' %istorm, imgResized)\n",
        "    elif inc == 2:\n",
        "      path = \"/content/Cat_Classifier_Images_70-30 /Test/Domino/\" + fil\n",
        "      img = cv2.imread(path)\n",
        "      idom += 1\n",
        "      imgResized = np.array((cv2.resize(img, (96, 128))))\n",
        "      cv2.imwrite('/content/Testing/Domino/DominoTR%03i.jpg' %idom, imgResized)\n",
        "    else:\n",
        "      path = \"/content/Cat_Classifier_Images_70-30 /Test/Stormy/\" + fil\n",
        "      img = cv2.imread(path)\n",
        "      istorm += 1\n",
        "      imgResized = np.array((cv2.resize(img, (96, 128))))\n",
        "      cv2.imwrite('/content/Testing/Stormy/StormyTR%03i.jpg' %istorm, imgResized)\n",
        "  inc += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x2K1Vz-5wqL"
      },
      "source": [
        "Data augmentation (Bounding Box csv has to be mounted before running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntThQKuurlPq"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "datadirDom = '/content/Training/Domino'\n",
        "datadirStorm = '/content/Training/Stormy'\n",
        "datadirDom2 = '/content/Testing/Domino'\n",
        "datadirStorm2 = '/content/Testing/Stormy'\n",
        "datadirDom = os.listdir(datadirDom)\n",
        "datadirStorm = os.listdir(datadirStorm)\n",
        "datadirDom2 = os.listdir(datadirDom2)\n",
        "datadirStorm2 = os.listdir(datadirStorm2)\n",
        "data = pd.read_csv('/content/CatBoxRegression - Sheet1.csv')\n",
        "labels = []\n",
        "cat_images = []\n",
        "Boxtrain = []\n",
        "classes = []\n",
        "def transformboxes(box, ref_hor, ref_vert):\n",
        "  if ref_hor:\n",
        "    box[0], box[2] = 1 - box[2], 1 - box[0]\n",
        "  if ref_vert:\n",
        "    box[1], box[3] = 1 - box[3], 1 - box[1]\n",
        "  return box\n",
        "i = 0\n",
        "for fil in datadirDom:\n",
        "  box = np.array((data['Startx'][i] / 96, data['Starty'][i] / 128, data['Endx'][i] / 96, data['Endy'][i] / 128))\n",
        "  i += 1\n",
        "  path = '/content/Training/Domino/' + fil\n",
        "  image = Image.open(path)\n",
        "  horz_image = np.array(image.transpose(method = Image.FLIP_LEFT_RIGHT))\n",
        "  vert_image = np.array(image.transpose(method = Image.FLIP_TOP_BOTTOM))\n",
        "  rot_image = np.array(image.rotate(180))\n",
        "  image = np.array(image)\n",
        "  cat_images.append(image)\n",
        "  cat_images.append(horz_image)\n",
        "  cat_images.append(vert_image)\n",
        "  cat_images.append(rot_image)\n",
        "  Boxtrain.append(box)\n",
        "  Boxtrain.append(transformboxes(box, True, False))\n",
        "  Boxtrain.append(transformboxes(box, False, True))\n",
        "  Boxtrain.append(transformboxes(box, True, True))\n",
        "  for j in range(4):\n",
        "    classes.append(np.array((1, 0)))\n",
        "for fil in datadirStorm:\n",
        "  box = np.array((data['Startx'][i] / 96, data['Starty'][i] / 128, data['Endx'][i] / 96, data['Endy'][i] / 128))\n",
        "  i += 1\n",
        "  path = '/content/Training/Stormy/' + fil\n",
        "  image = Image.open(path)\n",
        "  horz_image = np.array(image.transpose(method = Image.FLIP_LEFT_RIGHT))\n",
        "  vert_image = np.array(image.transpose(method = Image.FLIP_TOP_BOTTOM))\n",
        "  rot_image = np.array(image.rotate(180))\n",
        "  image = np.array(image)\n",
        "  cat_images.append(image)\n",
        "  cat_images.append(horz_image)\n",
        "  cat_images.append(vert_image)\n",
        "  cat_images.append(rot_image)\n",
        "  Boxtrain.append(box)\n",
        "  Boxtrain.append(transformboxes(box, True, False))\n",
        "  Boxtrain.append(transformboxes(box, False, True))\n",
        "  Boxtrain.append(transformboxes(box, True, True))\n",
        "  for j in range(4):\n",
        "    classes.append(np.array((0, 1)))\n",
        "for fil in datadirDom2:\n",
        "  box = np.array((data['Startx'][i] / 96, data['Starty'][i] / 128, data['Endx'][i] / 96, data['Endy'][i] / 128))\n",
        "  i += 1\n",
        "  path = '/content/Testing/Domino/' + fil\n",
        "  image = Image.open(path)\n",
        "  horz_image = np.array(image.transpose(method = Image.FLIP_LEFT_RIGHT))\n",
        "  vert_image = np.array(image.transpose(method = Image.FLIP_TOP_BOTTOM))\n",
        "  rot_image = np.array(image.rotate(180))\n",
        "  image = np.array(image)\n",
        "  cat_images.append(image)\n",
        "  cat_images.append(horz_image)\n",
        "  cat_images.append(vert_image)\n",
        "  cat_images.append(rot_image)\n",
        "  Boxtrain.append(box)\n",
        "  Boxtrain.append(transformboxes(box, True, False))\n",
        "  Boxtrain.append(transformboxes(box, False, True))\n",
        "  Boxtrain.append(transformboxes(box, True, True))\n",
        "  for j in range(4):\n",
        "    classes.append(np.array((1, 0)))\n",
        "for fil in datadirStorm2:\n",
        "  box = np.array((data['Startx'][i] / 96, data['Starty'][i] / 128, data['Endx'][i] / 96, data['Endy'][i] / 128))\n",
        "  i += 1\n",
        "  path = '/content/Testing/Stormy/' + fil\n",
        "  image = Image.open(path)\n",
        "  horz_image = np.array(image.transpose(method = Image.FLIP_LEFT_RIGHT))\n",
        "  vert_image = np.array(image.transpose(method = Image.FLIP_TOP_BOTTOM))\n",
        "  rot_image = np.array(image.rotate(180))\n",
        "  image = np.array(image)\n",
        "  cat_images.append(image)\n",
        "  cat_images.append(horz_image)\n",
        "  cat_images.append(vert_image)\n",
        "  cat_images.append(rot_image)\n",
        "  Boxtrain.append(box)\n",
        "  Boxtrain.append(transformboxes(box, True, False))\n",
        "  Boxtrain.append(transformboxes(box, False, True))\n",
        "  Boxtrain.append(transformboxes(box, True, True))\n",
        "  for j in range(4):\n",
        "    classes.append(np.array((0, 1)))\n",
        "cat_images = np.array(cat_images)\n",
        "Boxtrain = np.array((Boxtrain))\n",
        "classes = np.array((classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ebg-8M5zQ0"
      },
      "source": [
        "Custom Convolutional Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-o8jqZdDEc"
      },
      "source": [
        "import numpy as np #Importing needed libraries\n",
        "from tensorflow import random\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten, Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "random.set_seed(seed)\n",
        "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(cat_images, Boxtrain, classes, test_size = 0.3)\n",
        "input = Input(shape = (128, 96, 3))\n",
        "conv = Conv2D(128, (3, 3), input_shape = (128, 96, 3), activation = 'relu')(input)\n",
        "conv = Conv2D(64, (3, 3), input_shape = (128, 96, 3), activation = 'relu')(conv)\n",
        "conv = MaxPool2D(2, 2)(conv)\n",
        "conv = Conv2D(64, (3, 3), input_shape = (128, 96, 3), activation = 'relu')(conv)\n",
        "conv = Conv2D(64, (3, 3), input_shape = (128, 96, 3), activation = 'relu')(conv)\n",
        "conv = MaxPool2D(2, 2)(conv)\n",
        "conv = Flatten()(conv)\n",
        "bbox = Dense(128, activation = 'relu')(conv)\n",
        "bbox = Dropout(rate = 0.05)(bbox)\n",
        "bbox = Dense(64, activation = 'relu')(bbox)\n",
        "bbox = Dropout(rate = 0.05)(bbox)\n",
        "bbox = Dense(64, activation = 'relu')(bbox)\n",
        "bbox = Dropout(rate = 0.05)(bbox)\n",
        "bbox = Dense(64, activation = 'relu')(bbox)\n",
        "bbox = Dropout(rate = 0.05)(bbox)\n",
        "bbox = Dense(64, activation = 'relu')(bbox)\n",
        "bbox = Dropout(rate = 0.05)(bbox)\n",
        "bbox = Dense(4, activation = 'sigmoid', name = 'Bbox_Fin')(bbox)\n",
        "clas = Dense(128, activation = 'relu')(conv)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(2, activation = 'sigmoid', name = 'Class_Fin')(clas)\n",
        "detector = Model(inputs = input, outputs = [bbox, clas], name = 'Non-pretrained_Detector')\n",
        "optimizer = optimizers.Adagrad(learning_rate = 1e-4)\n",
        "detector.compile(optimizer = optimizer, loss = 'mse', metrics = ['accuracy'])\n",
        "print (detector.summary())\n",
        "epochs = [i for i in range(1000)]\n",
        "history = detector.fit(X_train, [y_train, z_train], validation_data = (X_test, [y_test, z_test]), validation_steps = 5, epochs = 1000, steps_per_epoch = 20, batch_size = 40, verbose = False)\n",
        "plt.scatter(epochs, history.history['val_loss'])\n",
        "plt.ylabel('Validaiton loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()\n",
        "plt.scatter(epochs, history.history['val_Bbox_Fin_accuracy'])\n",
        "plt.ylabel(\"Bounding box Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()\n",
        "plt.scatter(epochs, history.history['val_Class_Fin_accuracy'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Classifier Accuracy\")\n",
        "plt.show()\n",
        "detector.save('MC_cat_detector.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfvLoQ206HZ-"
      },
      "source": [
        "Using VGG16 Imagenet weights for cat bounding box detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYdXAQuZrqOf"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "import numpy as np #Importing needed libraries\n",
        "from tensorflow import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "random.set_seed(seed)\n",
        "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(cat_images, Boxtrain, classes, test_size = 0.3)\n",
        "vgg = VGG16(weights = 'imagenet', include_top = False, input_tensor = Input(shape = (128, 96, 3)))\n",
        "vgg.trainable = False\n",
        "result = vgg.output\n",
        "result = Flatten()(result)\n",
        "clas = Dense(128, activation = 'relu')(result)\n",
        "result = Dense(128, activation = 'relu')(result)\n",
        "result = Dropout(rate = 0.1)(result)\n",
        "result = Dense(64, activation = 'relu')(result)\n",
        "result = Dropout(rate = 0.1)(result)\n",
        "result = Dense(64, activation = 'relu')(result)\n",
        "result = Dropout(rate = 0.1)(result)\n",
        "result = Dense(64, activation = 'relu')(result)\n",
        "result = Dropout(rate = 0.1)(result)\n",
        "result = Dense(4, activation = 'sigmoid', name = 'Box_fin')(result)\n",
        "clas = Dropout(rate = 0.1)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(64, activation = 'relu')(clas)\n",
        "clas = Dropout(rate = 0.05)(clas)\n",
        "clas = Dense(2, activation = 'sigmoid', name = 'Clas_fin')(clas)\n",
        "detector = Model(inputs = vgg.input, outputs = [result, clas], name = 'Pretrained_ImageNet_Weights_Detector')\n",
        "optimizer = optimizers.Adam(learning_rate = 1e-4)\n",
        "detector.compile(optimizer = optimizer, loss = 'mse', metrics = ['accuracy'])\n",
        "print (detector.summary())\n",
        "epochs = [i for i in range(1000)]\n",
        "historyy = detector.fit(X_train, [y_train, z_train], validation_data = (X_test, [y_test, z_test]), validation_steps = 5, epochs = 1000, steps_per_epoch = 20, batch_size = 40, verbose = False)\n",
        "plt.scatter(epochs, historyy.history['val_loss'])\n",
        "plt.ylabel('Validaiton loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()\n",
        "plt.scatter(epochs, historyy.history['val_Box_fin_accuracy'])\n",
        "plt.ylabel(\"Bounding box Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()\n",
        "plt.scatter(epochs, historyy.history['val_Clas_fin_accuracy'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Classifier Accuracy\")\n",
        "plt.show()\n",
        "plt.scatter(epochs, historyy.history['Box_fin_accuracy'])\n",
        "plt.ylabel(\"Bounding box Training Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()\n",
        "detector.save('MC_vgg16_cat_detector.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNung3LI6BbA"
      },
      "source": [
        "Plotting Imagenet vs. non-Imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGbHmBRU3yuu"
      },
      "source": [
        "plt.scatter(epochs, historyy.history['val_loss'], label = 'Pretrained Conv')\n",
        "plt.ylabel('Validaiton loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.scatter(epochs, history.history['val_loss'], label = 'Non-pretrained Conv')\n",
        "plt.ylabel('Validaiton loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.scatter(epochs, historyy.history['val_Box_fin_accuracy'], label = 'Pretrained Conv')\n",
        "plt.ylabel(\"Bounding box Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.scatter(epochs, history.history['val_Bbox_Fin_accuracy'], label = 'Non-pretrained Conv')\n",
        "plt.ylabel(\"Bounding box Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.scatter(epochs, historyy.history['val_Clas_fin_accuracy'], label = 'Pretrained Conv')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Classifier Accuracy\")\n",
        "plt.scatter(epochs, history.history['val_Class_Fin_accuracy'], label = 'Non-pretrained Conv')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Classifier Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f_l1vF1oKvd"
      },
      "source": [
        "Bounding box prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLSieW4UkiVf"
      },
      "source": [
        "from keras.models import load_model\n",
        "detector = load_model('/content/MC_cat_detector.h5')\n",
        "image1 = np.array((cv2.resize(cv2.imread('/content/Testing/Domino/DominoTR128.jpg'), (96, 128))))\n",
        "image2 = np.array((cv2.resize(cv2.imread('/content/Testing/Stormy/StormyTR117.jpg'), (96, 128))))\n",
        "images = np.array((image1, image2))\n",
        "boxes, classes = detector.predict(images)\n",
        "def resize_box(box, h, w):\n",
        "  i = 0\n",
        "  boxx = []\n",
        "  for b in box:\n",
        "    if i % 2 == 0:\n",
        "      b = b * w\n",
        "      boxx.append(b)\n",
        "    else:\n",
        "      b = b * h\n",
        "      boxx.append(b)\n",
        "  return boxx\n",
        "boxess = []\n",
        "for box in boxes:\n",
        "  box = resize_box(box, 128, 96)\n",
        "  boxess.append(box)\n",
        "i = 0\n",
        "for image in images:\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "  print (boxess[i])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}